{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZfiL39OTJ5sR"
   },
   "source": [
    "# Hive assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VD19-0y3J5sR"
   },
   "source": [
    "The purpose of this task is to create an external table on the posts data of the `stackoverflow.com` website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKx3tQ4_J5sS"
   },
   "source": [
    "## Step 1. Intro. Creation of the DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "10mBFHfPJ5sS"
   },
   "source": [
    "Let's create the sandbox database where you will complete your assignment.\n",
    "\n",
    "<b>Note!</b> This code shouldn't be in your submission. Please, remove this code from the notebook before submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v1kw1lFXJ5sU",
    "outputId": "7fa089c4-ee8f-40ec-b220-5101298f1b18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting creation_db.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile creation_db.hql\n",
    "DROP DATABASE IF EXISTS poststaskdb CASCADE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gk869885J5sZ",
    "outputId": "7c890932-c8de-41ba-ad23-f3b966198693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting creation_db.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile creation_db.hql\n",
    "CREATE DATABASE poststaskdb LOCATION '/user/jovyan/test_metastore';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NvsrnOe6J5se"
   },
   "source": [
    "**Don't forget to remove this code before submission!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dPEiXPuAJ5sf"
   },
   "source": [
    "## Step 2. Exploration of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdzmqWgQJ5sg"
   },
   "source": [
    "Okay, we have created the database. Let's create your own table for users and posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Li8EZVxtJ5sg"
   },
   "source": [
    "First of all, let's watch at the datasets for `users` which are located at `/data/stackexchange1000/posts` and for `posts` which is located at `/data/stackexchange1000/users`. Print the first three rows of those datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HBbrpNdIeM6e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
      "reporter:status:Reading \t\n",
      "<row Id=\"1394\" PostTypeId=\"2\" ParentId=\"1390\" CreationDate=\"2008-08-04T16:38:03.667\" Score=\"16\" Body=\"&lt;p&gt;Not sure how credible &lt;a href=&quot;http://www.builderau.com.au/program/windows/soa/Getting-started-with-Windows-Server-2008-Core-edition/0,339024644,339288700,00.htm&quot; rel=&quot;nofollow noreferrer&quot;&gt;this source is&lt;/a&gt;, but:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The Windows Server 2008 Core edition can:&lt;/p&gt;&#xA;  &#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the file server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the Hyper-V virtualization server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the Directory Services role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the DHCP server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the IIS Web server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the DNS server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run Active Directory Lightweight Directory Services.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the print server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;  &#xA;  &lt;p&gt;The Windows Server 2008 Core edition cannot:&lt;/p&gt;&#xA;  &#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run a SQL Server.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run an Exchange Server.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run Internet Explorer.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run Windows Explorer.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Host a remote desktop session.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run MMC snap-in consoles locally.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;\" OwnerUserId=\"91\" LastEditorUserId=\"1\" LastEditorDisplayName=\"Jeff Atwood\" LastEditDate=\"2008-08-27T13:02:50.273\" LastActivityDate=\"2008-08-27T13:02:50.273\" CommentCount=\"1\" />\t\n",
      "<row Id=\"3543\" PostTypeId=\"2\" ParentId=\"3530\" CreationDate=\"2008-08-06T15:24:00.787\" Score=\"37\" Body=\"&lt;p&gt;from &lt;a href=&quot;http://www.timocracy.com/articles/2008/02/21/calling-invoking-rails-rake-tasks-from-within-ruby-for-testing-try-2&quot; rel=&quot;nofollow noreferrer&quot;&gt;timocracy.com&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;require 'rake'&#xA;require 'rake/rdoctask'&#xA;require 'rake/testtask'&#xA;require 'tasks/rails'&#xA;&#xA;def capture_stdout&#xA;  s = StringIO.new&#xA;  oldstdout = $stdout&#xA;  $stdout = s&#xA;  yield&#xA;  s.string&#xA;ensure&#xA;  $stdout = oldstdout&#xA;end&#xA;&#xA;Rake.application.rake_require '../../lib/tasks/metric_fetcher'&#xA;results = capture_stdout {Rake.application['metric_fetcher'].invoke}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;\" OwnerUserId=\"399\" LastActivityDate=\"2008-08-06T15:24:00.787\" CommentCount=\"3\" />\t\n",
      "<row Id=\"4521\" PostTypeId=\"2\" ParentId=\"66\" CreationDate=\"2008-08-07T08:22:27.440\" Score=\"25\" Body=\"&lt;p&gt;A few months back I wrote a blog post about  Fluent Interfaces and LINQ which used an Extension Method on &lt;code&gt;IQueryable&amp;lt;T&amp;gt;&lt;/code&gt; and another class to provide the following natural way of paginating a LINQ collection.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;var query = from i in ideas&#xA;            select i;&#xA;var pagedCollection = query.InPagesOf(10);&#xA;var pageOfIdeas = pagedCollection.Page(2);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;You can get the code from the MSDN Code Gallery Page: &lt;a href=&quot;http://code.msdn.microsoft.com/productschallenge&quot; rel=&quot;nofollow noreferrer&quot;&gt;Pipelines, Filters, Fluent API and LINQ to SQL&lt;/a&gt;.&lt;/p&gt;&#xA;\" OwnerUserId=\"358\" LastEditorUserId=\"1105514\" LastEditorDisplayName=\"Mitch Wheat\" LastEditDate=\"2012-08-09T14:59:49.197\" LastActivityDate=\"2012-08-09T14:59:49.197\" CommentCount=\"0\" />\t\n",
      "<row Id=\"8689\" PostTypeId=\"2\" ParentId=\"8685\" CreationDate=\"2008-08-12T11:23:28.733\" Score=\"1\" Body=\"&lt;p&gt;Kevin, you work off a solid absolute base (i.e. a date / time), not a relative time period. You then convert to the relative time periods. So, for example, by default, if you were showing a calendar, you'd work from todays date. &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;int strtotime  ( string $time  [, int $now  ] )&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;You can see in the function definition here of strtotime, the second argument is now, i.e. you can change the date from which it's relative.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This might be easier to display through a quick loop&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This will loop through the last 10 days using &quot;yesterday&quot; as the first argument. We then use date to print it out.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;$time = time();&#xA;&#xA;for ($i = 0; $i &amp;lt; 10; $i++) {&#xA;    $time = strtotime(&quot;yesterday&quot;, $time);&#xA;    print date(&quot;r&quot;, $time) . &quot;\\n&quot;;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;So pass the time/date in via the URI so you can save the relative date. &lt;/p&gt;&#xA;\" OwnerUserId=\"1087\" OwnerDisplayName=\"Phil\" LastActivityDate=\"2008-08-12T11:23:28.733\" CommentCount=\"0\" />\t\n",
      "<row Id=\"9062\" PostTypeId=\"2\" ParentId=\"6613\" CreationDate=\"2008-08-12T17:20:41.993\" Score=\"1\" Body=\"&lt;p&gt;I've &lt;a href=&quot;http://dlinsin.blogspot.com/2006/11/jboss-rules-example.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;checked out&lt;/a&gt; JBoss Rules aka Drools and it looks pretty good. I'd love to hear from people using it in production, because I'm probably gonna need a rule engine in my current project as well.&lt;/p&gt;&#xA;\" OwnerUserId=\"198\" OwnerDisplayName=\"david\" LastActivityDate=\"2008-08-12T17:20:41.993\" CommentCount=\"0\" />\t\n",
      "<row Id=\"14671\" PostTypeId=\"2\" ParentId=\"14577\" CreationDate=\"2008-08-18T14:18:22.310\" Score=\"1\" Body=\"&lt;p&gt;Unless you are willing to duplicate the code in the xref proc, there is no way to avoid using a cursor.&lt;/p&gt;&#xA;\" OwnerUserId=\"414\" OwnerDisplayName=\"Stu\" LastActivityDate=\"2008-08-18T14:18:22.310\" CommentCount=\"0\" />\t\n",
      "<row Id=\"16307\" PostTypeId=\"2\" ParentId=\"16298\" CreationDate=\"2008-08-19T14:45:07.997\" Score=\"2\" Body=\"&lt;p&gt;It sounds like the web server on hosttwo.com doesn't allow undefined domains to be passed through.  You also said you wanted to do a redirect, this isn't actually a method for redirecting.  If you bought this domain through GoDaddy you may just want to use their redirection service.&lt;/p&gt;&#xA;\" OwnerUserId=\"17\" OwnerDisplayName=\"Nick Berardi\" LastActivityDate=\"2008-08-19T14:45:07.997\" CommentCount=\"0\" />\t\n",
      "<row Id=\"18780\" PostTypeId=\"2\" ParentId=\"18772\" CreationDate=\"2008-08-20T20:44:27.947\" Score=\"0\" Body=\"&lt;p&gt;Have you tried connecting when logged on as domain/server-local Administrator?&lt;/p&gt;&#xA;\" OwnerUserId=\"414\" OwnerDisplayName=\"Stu\" LastActivityDate=\"2008-08-20T20:44:27.947\" CommentCount=\"0\" />\t\n",
      "<row Id=\"18929\" PostTypeId=\"2\" ParentId=\"18912\" CreationDate=\"2008-08-20T21:49:23.203\" Score=\"13\" Body=\"&lt;p&gt;This is the best you can do, as far as I know...&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;var keys = [];&#xA;for (var k in h)keys.push(k);&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;\" OwnerUserId=\"2031\" OwnerDisplayName=\"danb\" LastActivityDate=\"2008-08-20T21:49:23.203\" CommentCount=\"2\" />\t\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /data/stackexchange1000/posts/part-00000 | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting creation_posts.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile creation_posts.hql\n",
    "DROP TABLE poststaskdb.POSTS;\n",
    "CREATE EXTERNAL TABLE poststaskdb.POSTS \n",
    "(Id String,Date String)\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.RegexSerDe'\n",
    "WITH SERDEPROPERTIES(\"input.regex\" = '.*(?<=\\\\brow Id\\\\b=\\\")(\\\\d+).*(?<=\\\\bCreationDate\\\\b=\\\")(\\\\d{4}-\\\\d{2}-\\\\d{2}).*')\n",
    "LOCATION '/data/stackexchange1000/posts'\n",
    "TBLPROPERTIES(\"skip.header.line.count\" = \"1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile load_data_posts.hql\n",
    "#LOAD DATA INPATH '/data/stackexchange1000/posts/' INTO TABLE demodb.POSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!hive -f load_data_posts.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting select_posts.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile select_posts.hql\n",
    "SELECT * FROM poststaskdb.POSTS LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bRiLxzoReZ7o",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
      "reporter:status:Reading \t\n",
      "<row Id=\"756\" Reputation=\"2358\" CreationDate=\"2008-08-08T15:31:50.013\" DisplayName=\"Simon Gillbee\" LastAccessDate=\"2016-12-09T15:38:03.453\" WebsiteUrl=\"http://simon.gillbee.com\" Location=\"Pearland, TX\" AboutMe=\"&lt;p&gt;Personally, I am a husband, step-father, grandfather, Christ-worshiper, singer, worship leader, computer programmer, reader, game player, kite flyer, generally all around fun guy (or that fungi?).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Professionally, I've been developing both commercial and proprietary systems for the last 20 years. These days I'm primarily writing enterprise-scale client and server software using .NET and loving it!&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;SOreadytohelp&lt;/h1&gt;&#xA;\" Views=\"478\" UpVotes=\"352\" DownVotes=\"25\" Age=\"45\" AccountId=\"587\" />\t\n",
      "<row Id=\"2050\" Reputation=\"4177\" CreationDate=\"2008-08-20T00:32:49.217\" DisplayName=\"Eric Platon\" LastAccessDate=\"2016-12-10T22:24:27.217\" WebsiteUrl=\"\" Location=\"Tokyo, Japan\" AboutMe=\"\" Views=\"387\" UpVotes=\"1045\" DownVotes=\"6\" Age=\"46\" AccountId=\"1533\" />\t\n",
      "<row Id=\"2702\" Reputation=\"445\" CreationDate=\"2008-08-24T15:52:48.143\" DisplayName=\"BillSaysThis\" LastAccessDate=\"2016-11-28T19:25:20.763\" WebsiteUrl=\"http://billsaysthis.com\" AboutMe=\"\" Views=\"153\" UpVotes=\"28\" DownVotes=\"0\" AccountId=\"1964\" />\t\n",
      "<row Id=\"5795\" Reputation=\"469\" CreationDate=\"2008-09-11T11:59:42.220\" DisplayName=\"henningst\" LastAccessDate=\"2016-12-09T14:06:55.317\" Location=\"Oslo, Norway\" AboutMe=\"\" Views=\"98\" UpVotes=\"22\" DownVotes=\"2\" AccountId=\"3947\" />\t\n",
      "<row Id=\"6174\" Reputation=\"2584\" CreationDate=\"2008-09-12T19:10:15.157\" DisplayName=\"Mark Elder\" LastAccessDate=\"2016-12-07T17:57:52.823\" WebsiteUrl=\"http://www.uaar.net\" Location=\"Rapid City, SD\" AboutMe=\"&lt;p&gt;I work for a small ISV in South Dakota providing desktop software to rural real estate appraisers.&lt;/p&gt;&#xA;&#xA;&lt;h1&gt;SOreadytohelp&lt;/h1&gt;&#xA;\" Views=\"235\" UpVotes=\"586\" DownVotes=\"4\" ProfileImageUrl=\"https://i.stack.imgur.com/MoEoZ.jpg?s=128&amp;g=1\" Age=\"40\" AccountId=\"4166\" />\t\n",
      "<row Id=\"12332\" Reputation=\"2718\" CreationDate=\"2008-09-16T13:59:57.553\" DisplayName=\"JBB\" LastAccessDate=\"2011-08-24T18:03:18.493\" WebsiteUrl=\"http://xfinitytv.comcast.net\" Location=\"Philadelphia, PA\" AboutMe=\"&lt;p&gt;Proof you &lt;em&gt;can&lt;/em&gt; learn unix having only been told how to log in, log out, and run 'man ' to see docs for that command. (Hint: Start with 'man man')&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.linkedin.com/in/batzel&quot; rel=&quot;nofollow&quot;&gt;http://www.linkedin.com/in/batzel&lt;/a&gt;&lt;/p&gt;&#xA;\" Views=\"263\" UpVotes=\"112\" DownVotes=\"8\" Age=\"44\" AccountId=\"7170\" />\t\n",
      "<row Id=\"14357\" Reputation=\"72371\" CreationDate=\"2008-09-16T23:23:24.623\" DisplayName=\"spender\" LastAccessDate=\"2016-12-10T14:25:39.257\" WebsiteUrl=\"http://radiotuna.com\" Location=\"United Kingdom\" AboutMe=\"&lt;p&gt;Tea afficionado, A.I. graduate, &lt;a href=&quot;https://bugzilla.mozilla.org/show_bug.cgi?id=869725&quot; rel=&quot;nofollow&quot;&gt;Mozillian&lt;/a&gt;, company director and CTO at &lt;a href=&quot;http://radiotuna.com&quot; rel=&quot;nofollow&quot;&gt;radiotuna.com&lt;/a&gt;. Come and listen!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I give my time here because I get so much more in return.&lt;/p&gt;&#xA;\" Views=\"5810\" UpVotes=\"2026\" DownVotes=\"1056\" ProfileImageUrl=\"https://i.stack.imgur.com/BGshb.png\" Age=\"43\" AccountId=\"8089\" />\t\n",
      "<row Id=\"17516\" Reputation=\"145889\" CreationDate=\"2008-09-18T10:29:51.940\" DisplayName=\"AnthonyWJones\" LastAccessDate=\"2016-11-22T13:49:03.680\" WebsiteUrl=\"http://geekswithblogs.net/codingbloke\" Location=\"Birmingham, United Kingdom\" AboutMe=\"&lt;p&gt;&lt;p&gt;General interests: C#, Javascript, Agile, Interaction Design&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;p&gt;Current interests:  Silverlight+Toolkit, Windows Phone 7.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;p&gt;Would like to know more about: WCF, EF, WPF, XNA, SQL 2008, ... the list is endless.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;p&gt;First to gain the Silverlight badges, now at Gold.&lt;/p&gt;&#xA;\" Views=\"12801\" UpVotes=\"5757\" DownVotes=\"233\" Age=\"50\" AccountId=\"9467\" />\t\n",
      "<row Id=\"17693\" Reputation=\"16635\" CreationDate=\"2008-09-18T13:46:50.907\" DisplayName=\"Matt\" LastAccessDate=\"2016-12-08T17:16:17.217\" WebsiteUrl=\"http://www.squaregear.net/\" Location=\"United States\" AboutMe=\"&lt;p&gt;I'm just some guy who does some programming stuff.&lt;/p&gt;&#xA;\" Views=\"832\" UpVotes=\"109\" DownVotes=\"0\" ProfileImageUrl=\"https://i.stack.imgur.com/JgeMc.png\" Age=\"44\" AccountId=\"9547\" />\t\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /data/stackexchange1000/users/part-00000 | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting creation_users.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile creation_users.hql\n",
    "DROP TABLE poststaskdb.Users;\n",
    "CREATE EXTERNAL TABLE poststaskdb.Users (Id String, CreationDate String, DisplayName String)\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.RegexSerDe'\n",
    "WITH SERDEPROPERTIES (\"input.regex\"=\".*(?<=\\\\brow Id\\\\b=\\\")(\\\\d+).*(?<=\\\\bCreationDate\\\\b=\\\")(\\\\d{4}-\\\\d{2}-\\\\d{2}).*(?<=\\\\bDisplayName\\\\b=\\\")(\\\\w+).*\")\n",
    "LOCATION '/data/stackexchange1000/users'\n",
    "TBLPROPERTIES('skip.header.line.count'=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting select_users.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile select_users.hql\n",
    "SELECT * FROM poststaskdb.Users LIMIT 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGrOQYgqJ5sn"
   },
   "source": [
    "As you can see, those rows contain some information about posts and users in XML format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AoNccKriJ5sp"
   },
   "source": [
    "<b>Question.</b> Which fields for users and posts do you think are the most important for the analysis? And for joining tables? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mWC_LHQJ5sr"
   },
   "source": [
    "<h3><b>Please, check your answer with this information!</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hcl3lLyJ5sq"
   },
   "source": [
    "So, the lines not started with the \"row\" tags should be ignored. The valid row contains the following fields and their order is not defined:\n",
    "\n",
    "* Id (integer) - id of the post\n",
    "* PostTypeId (integer: 1 or 2) - 1 for questions, 2 for answers\n",
    "* CreationDate (date) - post creation date in the format \"YYYY-MM-DDTHH:MM:SS.ms\"\n",
    "* Tags (string, optional) - list of post tags, each tag is wrapped with html entities `&lt;` and `&gt;`\n",
    "* OwnerUserId (integer, optional) - user id of the post's author\n",
    "* ParentId (integer, optional) - for answers - id of the question\n",
    "* Score (integer) - score (votes) of a question or an answer, can be negative (!)\n",
    "* FavoriteCount (integer, optional) - how many times the question was added in the favorites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmQ2vtOVJ5sr"
   },
   "source": [
    "The second part of the dataset contains StackOverflow users.\n",
    "\n",
    "The fields are the following and their order is also not defined:\n",
    "\n",
    "* Id (integer) - user id\n",
    "* Reputation (integer) - user's reputation\n",
    "* CreationDate (string) - creation date in the format \"YYYY-MM-DDTHH:MM:SS.ms\"\n",
    "* DisplayName (string) - user's name\n",
    "* Location (string, options) - user's country\n",
    "* Age (integer, optional) - user's age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Na2THNHnJ5ss"
   },
   "source": [
    "## Step 3. Train your regexp skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxFZQpxIJ5st"
   },
   "source": [
    "In this step you will find out how to parse information for complex rows! You will try to create some examples for parsing! There are some general rules for parsing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRaJBzTeJ5su"
   },
   "source": [
    "1. To create a regular expression, which describes strings containing two patterns, where the order of the patterns is not defined use the following so-called ‘positive lookahead assertion’ with `?=` group modifier. For example, both strings “Washington Irving” and “Irving Washington” match the pattern:\n",
    "```\n",
    "(?=.*Washington)(?=.*Irving)\n",
    "```.\n",
    "2. To capture groups use round brackets. So, the pattern: `(?=.*(Washington))(?=.*(Irving))` captures `Washington` and `Irving` from both strings: \"William Arthur Irving Washington was an English first-class Cricketer\" and: “Washington Irving was an American writer”.\n",
    "3. Use `\\b` to specify boundaries of words and increase accuracy of your pattern. For example: pattern `(?=.*\\bID=(\\d+))(?=.*\\bUserID=(\\d+))` captures `1` and `2` from the string `ID=1 UserID=2`, whereas pattern without `\\b`: `(?=.*ID=(\\d+))(?=.*UserID=(\\d+))` returns the wrong groups: `2` and `2`.\n",
    "4. In Hive pattern for the external table in SERDEPROPERTIES `input.regex` should describe the whole input string, add `.*` at the end of the pattern.\n",
    "5. Don't forget that for the beginning of string should also be covered. That's why use the pattern `.*?` for lazy initialization of future patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cRobnWBYJ5sv"
   },
   "source": [
    "To sum up, you can create your first regex for parsing Id from posts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fA7LBThaJ5sv"
   },
   "source": [
    "<b>Question!</b> What will be your first regex for parsing Id from the posts? Don't forget to add steps 4 and 5!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAwyKE9EJ5sw"
   },
   "source": [
    "<div class=\"panel-group\">\n",
    "  <div class=\"panel panel-default\">\n",
    "    <div class=\"panel-heading\">\n",
    "      <h4 class=\"panel-title\">\n",
    "        <a data-toggle=\"collapse\" href=\"#collapse-answer\">Check your answer!</a>\n",
    "      </h4>\n",
    "    </div>\n",
    "    <div id=\"collapse-answer\" class=\"panel-collapse collapse\">\n",
    "      <div class=\"panel-body\">The correct answer is `\".*?(?=.*\\\\bId=\\\"(\\\\d+)\\\").*\"` </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pirvGNs1J5sx"
   },
   "source": [
    "Let's create the first external table with one row which contains only `Id` field. Let's name it `posts_external_only_id`.\n",
    "You can watch the lecture for the SerDe format: <a href=\"https://www.coursera.org/learn/big-data-analysis/lecture/wAGe6/hive-analytics-regexserde-views\">Serde Format</a> and <a href=\"/notebooks/demos/course02_week02-Demo_submission.ipynb#2.-Creation-the-external-table\">creation of external table</a> tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bMdai9W-J5sx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demo_example.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile demo_example.hql\n",
    "\n",
    "-- adding necessary JARs and including database\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar;\n",
    "\n",
    "USE poststaskdb;\n",
    "DROP TABLE IF EXISTS posts_external_only_id;\n",
    "\n",
    "\n",
    "-- Create external table \n",
    "\n",
    "CREATE EXTERNAL TABLE posts_external_only_id (Id String)\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.RegexSerDe'\n",
    "WITH SERDEPROPERTIES(\"input.regex\" = '.*(?<=\\\\brow Id\\\\b=\\\")(\\\\d+).*')\n",
    "LOCATION '/data/stackexchange1000/posts'\n",
    "TBLPROPERTIES(\"skip.header.line.count\" = \"1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lNqp7uWJ5s9"
   },
   "source": [
    "Hooray! You have created your first table. Let us watch for this table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Z4m1NcvkJ5s9",
    "outputId": "fb1d255e-e8e6-495d-bdb9-aef62dce66d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting describe.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile describe.hql\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "\n",
    "USE poststaskdb;\n",
    "DESCRIBE posts_external_only_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuvkMUIqJ5tE"
   },
   "source": [
    "Let's see that the data is  correctly parsed. For this case, take a select query that chooses for us first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZkONpnbTJ5tF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my_first_select.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_first_select.hql\n",
    "\n",
    "USE poststaskdb;\n",
    "SELECT * FROM posts_external_only_id LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xFL5R6oTJ5tO"
   },
   "source": [
    "How many posts are there in the dataset? Don't forget to clear the `NULL` values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "d0gg-zzyJ5tO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting how_many_posts.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile how_many_posts.hql\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "\n",
    "USE poststaskdb;\n",
    "SELECT COUNT(*) FROM posts_external_only_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjP7lEGZJ5tW"
   },
   "source": [
    "Try to parse different fields: for example, day and month of creation date. Don't forget that Hive will accept values for the capturing group in the lookahead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ai72gzOJ5tX"
   },
   "source": [
    "Now you are ready to complete your task! Before this you can check your regular expression for parsing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RK4ni3GdJ5tY"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yT8UyDAKJ5tZ"
   },
   "outputs": [],
   "source": [
    "CHECK_ROW = '<row Id=\"1394\" PostTypeId=\"2\" ParentId=\"1390\" CreationDate=\"2008-08-04T16:38:03.667\" Score=\"16\" Body=\"&lt;p&gt;Not sure how credible &lt;a href=&quot;http://www.builderau.com.au/program/windows/soa/Getting-started-with-Windows-Server-2008-Core-edition/0,339024644,339288700,00.htm&quot; rel=&quot;nofollow noreferrer&quot;&gt;this source is&lt;/a&gt;, but:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The Windows Server 2008 Core edition can:&lt;/p&gt;&#xA;  &#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the file server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the Hyper-V virtualization server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the Directory Services role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the DHCP server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the IIS Web server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the DNS server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run Active Directory Lightweight Directory Services.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run the print server role.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;  &#xA;  &lt;p&gt;The Windows Server 2008 Core edition cannot:&lt;/p&gt;&#xA;  &#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run a SQL Server.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run an Exchange Server.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run Internet Explorer.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run Windows Explorer.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Host a remote desktop session.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;li&gt;&lt;p&gt;Run MMC snap-in consoles locally.&lt;/p&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;\" OwnerUserId=\"91\" LastEditorUserId=\"1\" LastEditorDisplayName=\"Jeff Atwood\" LastEditDate=\"2008-08-27T13:02:50.273\" LastActivityDate=\"2008-08-27T13:02:50.273\" CommentCount=\"1\" />'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CGLH3FM_J5tb"
   },
   "outputs": [],
   "source": [
    "CHECK_REGEX = '.*(?<=\\\\bCreationDate\\\\b=\\\")(\\\\d{4}-\\\\d{2}).*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "P8ZiiwbqJ5tf"
   },
   "outputs": [],
   "source": [
    "result = re.match(CHECK_REGEX, CHECK_ROW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 1887), match='<row Id=\"1394\" PostTypeId=\"2\" ParentId=\"1390\" Cre>"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lKWMRzJNJ5ti"
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert result.group(0) == CHECK_ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JeTfyTUwJ5tk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2008-08',)\n"
     ]
    }
   ],
   "source": [
    "# Check that your groups are correct\n",
    "print(result.groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agtKfzx2J5tm"
   },
   "source": [
    "## Step 4. Complete the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jRdQeLwkJ5tn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task1_create_external_table.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile task1_create_external_table.hql\n",
    "USE poststaskdb;\n",
    "\n",
    "DROP TABLE IF EXISTS posts_sample_external;\n",
    "\n",
    "CREATE EXTERNAL TABLE posts_sample_external (Id String,Year String,Month String)\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.RegexSerDe'\n",
    "WITH SERDEPROPERTIES('input.regex' = '.*(?<=\\\\brow Id\\\\b=\\\")(\\\\d+).*(?<=\\\\bCreationDate\\\\b=\\\")(\\\\d{4})-(\\\\d{2}).*')\n",
    "LOCATION '/data/stackexchange1000/posts'\n",
    "TBLPROPERTIES('skip.header.line.count' = '1');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaImIBNKJ5ts"
   },
   "source": [
    "Make sure that you have created your table correctly. Select the first 10 posts from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2LdLWs-cJ5tt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task1_check_select.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile task1_check_select.hql\n",
    "USE poststaskdb;\n",
    "\n",
    "SELECT * FROM posts_sample_external LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqfA8StqJ5tx"
   },
   "source": [
    "Create managed table `posts_sample`. Create the partition by the month and by the year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YUNkq4SXJ5t0"
   },
   "source": [
    "Populate data from the table `posts_sample_external` to the table `posts_sample`. Don't forget about the partitioning rules!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HdCM4rS7J5t0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task1_insert_table.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile task1_insert_table.hql\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "SET hive.exec.dynamic.partition.mode=nonstrict;\n",
    "\n",
    "USE poststaskdb;\n",
    "DROP TABLE IF EXISTS posts_sample;\n",
    "\n",
    "CREATE TABLE posts_sample (Id int) \n",
    "PARTITIONED BY (Month INT,Year  INT);\n",
    "\n",
    "FROM posts_sample_external\n",
    "INSERT OVERWRITE TABLE posts_sample\n",
    "PARTITION (Month, Year)\n",
    "SELECT Id, Month, Year;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QZWORJwJ5t4"
   },
   "source": [
    "Make sure that your table contains appropriate data about posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1ySBr38iJ5t7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task1_watch_new_table.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile task1_watch_new_table.hql\n",
    "\n",
    "USE poststaskdb;\n",
    "\n",
    "SELECT * FROM posts_sample LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6qpvRyrvJ5t_"
   },
   "source": [
    "Take the third row of the dataset in the ascending order for the posts (firstly by year, after that by month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IptrKDK8J5t_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task1_result.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile task1_result.hql\n",
    "\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "\n",
    "USE poststaskdb;\n",
    "\n",
    "SELECT CONCAT_WS(\"\\t\",String(Year),CONCAT_WS(\"-\",String(Year),String(Month)),String(count)) FROM (\n",
    "SELECT ROW_NUMBER() OVER(ORDER BY Year,Month) as RowNum,* FROM \n",
    "(SELECT Year,Month,COUNT(Id) as count \n",
    "FROM posts_sample \n",
    "GROUP BY Year,Month \n",
    "ORDER BY Year,Month) t1 ) t2 WHERE RowNum = 3;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar]\n",
      "OK\n",
      "Time taken: 0.45 seconds\n",
      "Query ID = jovyan_20190218094242_d922bd4e-f618-4081-a5a5-cea5c2468e86\n",
      "Total jobs = 3\n",
      "Launching Job 1 out of 3\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1550229492569_0065, Tracking URL = http://82cdaacd7b39:8088/proxy/application_1550229492569_0065/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1550229492569_0065\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2019-02-18 09:42:39,416 Stage-1 map = 0%,  reduce = 0%\n",
      "2019-02-18 09:42:44,693 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.67 sec\n",
      "2019-02-18 09:42:49,989 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 2.82 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 820 msec\n",
      "Ended Job = job_1550229492569_0065\n",
      "Launching Job 2 out of 3\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1550229492569_0066, Tracking URL = http://82cdaacd7b39:8088/proxy/application_1550229492569_0066/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1550229492569_0066\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2019-02-18 09:43:01,347 Stage-2 map = 0%,  reduce = 0%\n",
      "2019-02-18 09:43:05,543 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 0.64 sec\n",
      "2019-02-18 09:43:10,698 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 1.63 sec\n",
      "MapReduce Total cumulative CPU time: 1 seconds 630 msec\n",
      "Ended Job = job_1550229492569_0066\n",
      "Launching Job 3 out of 3\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1550229492569_0067, Tracking URL = http://82cdaacd7b39:8088/proxy/application_1550229492569_0067/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1550229492569_0067\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "2019-02-18 09:43:22,458 Stage-3 map = 0%,  reduce = 0%\n",
      "2019-02-18 09:43:26,598 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 0.69 sec\n",
      "2019-02-18 09:43:31,799 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.32 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 320 msec\n",
      "Ended Job = job_1550229492569_0067\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 2.82 sec   HDFS Read: 387896 HDFS Write: 2499 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 1.63 sec   HDFS Read: 6488 HDFS Write: 2499 SUCCESS\n",
      "Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 2.32 sec   HDFS Read: 9638 HDFS Write: 16 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 6 seconds 770 msec\n",
      "OK\n",
      "2008\t2008-10\t73\n",
      "Time taken: 60.62 seconds, Fetched: 1 row(s)\n"
     ]
    }
   ],
   "source": [
    "!hive -f task1_result.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJTsCVTkJ5uC"
   },
   "source": [
    "## Step 5. Submission part. Do not touch!! And simple run all cells below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k90P-CwSJ5uC"
   },
   "source": [
    "Copy your notebook from the steps <a href=\"#Step-4.-Complete-the-assignment\">Step 4</a> and <a href=\"#Step-5.-Submission-part.-Do-not-touch!!-And-simple-run-all-cells-below!\">Step 5</a> to the new notebook. Run all the cells! And submit the copied notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KK3zjw7EJ5uF"
   },
   "source": [
    "Take a look at your submission query!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat task1_create_external_table.hql > task1.hql\n",
    "!cat task1_insert_table.hql >> task1.hql\n",
    "!cat task1_result.hql >> task1.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CLawbwF4J5uG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE poststaskdb;\r\n",
      "\r\n",
      "DROP TABLE IF EXISTS posts_sample_external;\r\n",
      "\r\n",
      "CREATE EXTERNAL TABLE posts_sample_external (Id String,Year String,Month String)\r\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.RegexSerDe'\r\n",
      "WITH SERDEPROPERTIES('input.regex' = '.*(?<=\\\\brow Id\\\\b=\\\")(\\\\d+).*(?<=\\\\bCreationDate\\\\b=\\\")(\\\\d{4})-(\\\\d{2}).*')\r\n",
      "LOCATION '/data/stackexchange1000/posts'\r\n",
      "TBLPROPERTIES('skip.header.line.count' = '1');\r\n",
      "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\r\n",
      "SET hive.exec.dynamic.partition.mode=nonstrict;\r\n",
      "\r\n",
      "USE poststaskdb;\r\n",
      "DROP TABLE IF EXISTS posts_sample;\r\n",
      "\r\n",
      "CREATE TABLE posts_sample (Id int) \r\n",
      "PARTITIONED BY (Month INT,Year  INT);\r\n",
      "\r\n",
      "FROM posts_sample_external\r\n",
      "INSERT OVERWRITE TABLE posts_sample\r\n",
      "PARTITION (Month, Year)\r\n",
      "SELECT Id, Month, Year;\r\n",
      "\r\n",
      "\r\n",
      "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\r\n",
      "\r\n",
      "USE poststaskdb;\r\n",
      "\r\n",
      "SELECT CONCAT_WS(\"\\t\",String(Year),CONCAT_WS(\"-\",String(Year),String(Month)),String(count)) FROM (\r\n",
      "SELECT ROW_NUMBER() OVER(ORDER BY Year,Month) as RowNum,* FROM \r\n",
      "(SELECT Year,Month,COUNT(Id) as count \r\n",
      "FROM posts_sample \r\n",
      "GROUP BY Year,Month \r\n",
      "ORDER BY Year,Month) t1 ) t2 WHERE RowNum = 3;"
     ]
    }
   ],
   "source": [
    "!cat task1.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GGO0BjtzJ5uI"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "$(document).ready(function() {\n",
       "    console.log('Ready');\n",
       "    \n",
       "    \n",
       "    function is_hive_command(list_tokens) {\n",
       "        return list_tokens.indexOf('hive') > -1 && \n",
       "             list_tokens.indexOf('f') > -1 &&\n",
       "             list_tokens.indexOf('-') > -1 && \n",
       "             list_tokens.indexOf('!') > -1 &&\n",
       "             list_tokens.indexOf('hql') > -1 && \n",
       "             list_tokens.indexOf('writefile') == -1;\n",
       "    } \n",
       "    \n",
       "    function collectText(input_tag) {\n",
       "\n",
       "        var result_string = [];\n",
       "        $.each($(input_tag).children(), function(index, child) {\n",
       "            result_string.push($(child).text());\n",
       "        });\n",
       "        return [result_string, is_hive_command(result_string)];\n",
       "    };\n",
       "    \n",
       "    var filtered_results = $(\".cell.code_cell.rendered\").filter(function(index, element) {\n",
       "        var out = collectText($(element).find('.CodeMirror-line').find('span'));\n",
       "        console.log(out);\n",
       "        return collectText($(element).find('.CodeMirror-line').find('span'))[1];\n",
       "    });\n",
       "    $(filtered_results).remove();\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "$(document).ready(function() {\n",
    "    console.log('Ready');\n",
    "    \n",
    "    \n",
    "    function is_hive_command(list_tokens) {\n",
    "        return list_tokens.indexOf('hive') > -1 && \n",
    "             list_tokens.indexOf('f') > -1 &&\n",
    "             list_tokens.indexOf('-') > -1 && \n",
    "             list_tokens.indexOf('!') > -1 &&\n",
    "             list_tokens.indexOf('hql') > -1 && \n",
    "             list_tokens.indexOf('writefile') == -1;\n",
    "    } \n",
    "    \n",
    "    function collectText(input_tag) {\n",
    "\n",
    "        var result_string = [];\n",
    "        $.each($(input_tag).children(), function(index, child) {\n",
    "            result_string.push($(child).text());\n",
    "        });\n",
    "        return [result_string, is_hive_command(result_string)];\n",
    "    };\n",
    "    \n",
    "    var filtered_results = $(\".cell.code_cell.rendered\").filter(function(index, element) {\n",
    "        var out = collectText($(element).find('.CodeMirror-line').find('span'));\n",
    "        console.log(out);\n",
    "        return collectText($(element).find('.CodeMirror-line').find('span'))[1];\n",
    "    });\n",
    "    $(filtered_results).remove();\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "unTiTnY_J5uK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\t2008-10\t73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 0.395 seconds\n",
      "OK\n",
      "Time taken: 0.652 seconds\n",
      "OK\n",
      "Time taken: 0.256 seconds\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar]\n",
      "OK\n",
      "Time taken: 0.009 seconds\n",
      "OK\n",
      "Time taken: 1.254 seconds\n",
      "OK\n",
      "Time taken: 0.174 seconds\n",
      "Query ID = jovyan_20190218093535_cae1428f-a794-4ca5-a9eb-a86d51938afe\n",
      "Total jobs = 3\n",
      "Launching Job 1 out of 3\n",
      "Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "Starting Job = job_1550229492569_0061, Tracking URL = http://82cdaacd7b39:8088/proxy/application_1550229492569_0061/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1550229492569_0061\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0\n",
      "2019-02-18 09:35:53,101 Stage-1 map = 0%,  reduce = 0%\n",
      "2019-02-18 09:36:08,793 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 10.06 sec\n",
      "MapReduce Total cumulative CPU time: 10 seconds 60 msec\n",
      "Ended Job = job_1550229492569_0061\n",
      "Stage-4 is selected by condition resolver.\n",
      "Stage-3 is filtered out by condition resolver.\n",
      "Stage-5 is filtered out by condition resolver.\n",
      "Moving data to: hdfs://localhost:9000/user/jovyan/test_metastore/posts_sample/.hive-staging_hive_2019-02-18_09-35-45_439_8692599297729934759-1/-ext-10000\n",
      "Loading data to table poststaskdb.posts_sample partition (month=null, year=null)\n",
      "\t Time taken for load dynamic partitions : 4527\n",
      "\tLoading partition {month=03, year=2014}\n",
      "\tLoading partition {month=10, year=2009}\n",
      "\tLoading partition {month=12, year=2015}\n",
      "\tLoading partition {month=10, year=2012}\n",
      "\tLoading partition {month=05, year=2011}\n",
      "\tLoading partition {month=08, year=2009}\n",
      "\tLoading partition {month=08, year=2012}\n",
      "\tLoading partition {month=04, year=2009}\n",
      "\tLoading partition {month=06, year=2015}\n",
      "\tLoading partition {month=02, year=2015}\n",
      "\tLoading partition {month=09, year=2010}\n",
      "\tLoading partition {month=02, year=2010}\n",
      "\tLoading partition {month=11, year=2011}\n",
      "\tLoading partition {month=06, year=2010}\n",
      "\tLoading partition {month=06, year=2016}\n",
      "\tLoading partition {month=01, year=2012}\n",
      "\tLoading partition {month=09, year=2016}\n",
      "\tLoading partition {month=05, year=2016}\n",
      "\tLoading partition {month=10, year=2013}\n",
      "\tLoading partition {month=02, year=2016}\n",
      "\tLoading partition {month=04, year=2012}\n",
      "\tLoading partition {month=01, year=2016}\n",
      "\tLoading partition {month=08, year=2011}\n",
      "\tLoading partition {month=09, year=2011}\n",
      "\tLoading partition {month=01, year=2011}\n",
      "\tLoading partition {month=11, year=2009}\n",
      "\tLoading partition {month=07, year=2009}\n",
      "\tLoading partition {month=09, year=2009}\n",
      "\tLoading partition {month=11, year=2012}\n",
      "\tLoading partition {month=07, year=2015}\n",
      "\tLoading partition {month=09, year=2015}\n",
      "\tLoading partition {month=01, year=2013}\n",
      "\tLoading partition {month=05, year=2015}\n",
      "\tLoading partition {month=01, year=2010}\n",
      "\tLoading partition {month=03, year=2009}\n",
      "\tLoading partition {month=03, year=2013}\n",
      "\tLoading partition {month=03, year=2015}\n",
      "\tLoading partition {month=03, year=2010}\n",
      "\tLoading partition {month=05, year=2009}\n",
      "\tLoading partition {month=05, year=2010}\n",
      "\tLoading partition {month=01, year=2009}\n",
      "\tLoading partition {month=08, year=2010}\n",
      "\tLoading partition {month=07, year=2013}\n",
      "\tLoading partition {month=05, year=2013}\n",
      "\tLoading partition {month=08, year=2013}\n",
      "\tLoading partition {month=01, year=2015}\n",
      "\tLoading partition {month=06, year=2013}\n",
      "\tLoading partition {month=04, year=2013}\n",
      "\tLoading partition {month=11, year=2010}\n",
      "\tLoading partition {month=10, year=2010}\n",
      "\tLoading partition {month=12, year=2010}\n",
      "\tLoading partition {month=12, year=2009}\n",
      "\tLoading partition {month=10, year=2015}\n",
      "\tLoading partition {month=11, year=2015}\n",
      "\tLoading partition {month=03, year=2011}\n",
      "\tLoading partition {month=12, year=2012}\n",
      "\tLoading partition {month=08, year=2015}\n",
      "\tLoading partition {month=06, year=2012}\n",
      "\tLoading partition {month=02, year=2009}\n",
      "\tLoading partition {month=02, year=2013}\n",
      "\tLoading partition {month=04, year=2015}\n",
      "\tLoading partition {month=11, year=2014}\n",
      "\tLoading partition {month=04, year=2010}\n",
      "\tLoading partition {month=06, year=2009}\n",
      "\tLoading partition {month=09, year=2013}\n",
      "\tLoading partition {month=07, year=2010}\n",
      "\tLoading partition {month=07, year=2016}\n",
      "\tLoading partition {month=08, year=2016}\n",
      "\tLoading partition {month=04, year=2016}\n",
      "\tLoading partition {month=11, year=2013}\n",
      "\tLoading partition {month=02, year=2012}\n",
      "\tLoading partition {month=03, year=2012}\n",
      "\tLoading partition {month=03, year=2016}\n",
      "\tLoading partition {month=12, year=2013}\n",
      "\tLoading partition {month=07, year=2011}\n",
      "\tLoading partition {month=06, year=2011}\n",
      "\tLoading partition {month=02, year=2011}\n",
      "\tLoading partition {month=04, year=2011}\n",
      "\tLoading partition {month=07, year=2012}\n",
      "\tLoading partition {month=09, year=2012}\n",
      "\tLoading partition {month=05, year=2012}\n",
      "\tLoading partition {month=10, year=2011}\n",
      "\tLoading partition {month=10, year=2014}\n",
      "\tLoading partition {month=12, year=2016}\n",
      "\tLoading partition {month=12, year=2014}\n",
      "\tLoading partition {month=12, year=2011}\n",
      "\tLoading partition {month=10, year=2016}\n",
      "\tLoading partition {month=11, year=2016}\n",
      "\tLoading partition {month=10, year=2008}\n",
      "\tLoading partition {month=11, year=2008}\n",
      "\tLoading partition {month=12, year=2008}\n",
      "\tLoading partition {month=08, year=2014}\n",
      "\tLoading partition {month=09, year=2014}\n",
      "\tLoading partition {month=06, year=2014}\n",
      "\tLoading partition {month=07, year=2014}\n",
      "\tLoading partition {month=01, year=2014}\n",
      "\tLoading partition {month=02, year=2014}\n",
      "\tLoading partition {month=05, year=2014}\n",
      "\tLoading partition {month=04, year=2014}\n",
      "\tLoading partition {month=08, year=2008}\n",
      "\tLoading partition {month=09, year=2008}\n",
      "\t Time taken for adding to write entity : 22\n",
      "Partition poststaskdb.posts_sample{month=01, year=2009} stats: [numFiles=1, numRows=84, totalSize=588, rawDataSize=504]\n",
      "Partition poststaskdb.posts_sample{month=01, year=2010} stats: [numFiles=1, numRows=175, totalSize=1400, rawDataSize=1225]\n",
      "Partition poststaskdb.posts_sample{month=01, year=2011} stats: [numFiles=1, numRows=276, totalSize=2208, rawDataSize=1932]\n",
      "Partition poststaskdb.posts_sample{month=01, year=2012} stats: [numFiles=1, numRows=377, totalSize=3016, rawDataSize=2639]\n",
      "Partition poststaskdb.posts_sample{month=01, year=2013} stats: [numFiles=1, numRows=484, totalSize=4356, rawDataSize=3872]\n",
      "Partition poststaskdb.posts_sample{month=01, year=2014} stats: [numFiles=1, numRows=595, totalSize=5355, rawDataSize=4760]\n",
      "Partition poststaskdb.posts_sample{month=01, year=2015} stats: [numFiles=1, numRows=502, totalSize=4518, rawDataSize=4016]\n",
      "Partition poststaskdb.posts_sample{month=01, year=2016} stats: [numFiles=1, numRows=582, totalSize=5238, rawDataSize=4656]\n",
      "Partition poststaskdb.posts_sample{month=02, year=2009} stats: [numFiles=1, numRows=84, totalSize=588, rawDataSize=504]\n",
      "Partition poststaskdb.posts_sample{month=02, year=2010} stats: [numFiles=1, numRows=162, totalSize=1296, rawDataSize=1134]\n",
      "Partition poststaskdb.posts_sample{month=02, year=2011} stats: [numFiles=1, numRows=273, totalSize=2184, rawDataSize=1911]\n",
      "Partition poststaskdb.posts_sample{month=02, year=2012} stats: [numFiles=1, numRows=412, totalSize=3296, rawDataSize=2884]\n",
      "Partition poststaskdb.posts_sample{month=02, year=2013} stats: [numFiles=1, numRows=474, totalSize=4266, rawDataSize=3792]\n",
      "Partition poststaskdb.posts_sample{month=02, year=2014} stats: [numFiles=1, numRows=585, totalSize=5265, rawDataSize=4680]\n",
      "Partition poststaskdb.posts_sample{month=02, year=2015} stats: [numFiles=1, numRows=506, totalSize=4554, rawDataSize=4048]\n",
      "Partition poststaskdb.posts_sample{month=02, year=2016} stats: [numFiles=1, numRows=592, totalSize=5328, rawDataSize=4736]\n",
      "Partition poststaskdb.posts_sample{month=03, year=2009} stats: [numFiles=1, numRows=85, totalSize=595, rawDataSize=510]\n",
      "Partition poststaskdb.posts_sample{month=03, year=2010} stats: [numFiles=1, numRows=190, totalSize=1520, rawDataSize=1330]\n",
      "Partition poststaskdb.posts_sample{month=03, year=2011} stats: [numFiles=1, numRows=349, totalSize=2792, rawDataSize=2443]\n",
      "Partition poststaskdb.posts_sample{month=03, year=2012} stats: [numFiles=1, numRows=432, totalSize=3456, rawDataSize=3024]\n",
      "Partition poststaskdb.posts_sample{month=03, year=2013} stats: [numFiles=1, numRows=533, totalSize=4797, rawDataSize=4264]\n",
      "Partition poststaskdb.posts_sample{month=03, year=2014} stats: [numFiles=1, numRows=624, totalSize=5616, rawDataSize=4992]\n",
      "Partition poststaskdb.posts_sample{month=03, year=2015} stats: [numFiles=1, numRows=568, totalSize=5112, rawDataSize=4544]\n",
      "Partition poststaskdb.posts_sample{month=03, year=2016} stats: [numFiles=1, numRows=638, totalSize=5742, rawDataSize=5104]\n",
      "Partition poststaskdb.posts_sample{month=04, year=2009} stats: [numFiles=1, numRows=97, totalSize=679, rawDataSize=582]\n",
      "Partition poststaskdb.posts_sample{month=04, year=2010} stats: [numFiles=1, numRows=179, totalSize=1432, rawDataSize=1253]\n",
      "Partition poststaskdb.posts_sample{month=04, year=2011} stats: [numFiles=1, numRows=321, totalSize=2568, rawDataSize=2247]\n",
      "Partition poststaskdb.posts_sample{month=04, year=2012} stats: [numFiles=1, numRows=412, totalSize=3672, rawDataSize=3260]\n",
      "Partition poststaskdb.posts_sample{month=04, year=2013} stats: [numFiles=1, numRows=529, totalSize=4761, rawDataSize=4232]\n",
      "Partition poststaskdb.posts_sample{month=04, year=2014} stats: [numFiles=1, numRows=593, totalSize=5337, rawDataSize=4744]\n",
      "Partition poststaskdb.posts_sample{month=04, year=2015} stats: [numFiles=1, numRows=581, totalSize=5229, rawDataSize=4648]\n",
      "Partition poststaskdb.posts_sample{month=04, year=2016} stats: [numFiles=1, numRows=619, totalSize=5571, rawDataSize=4952]\n",
      "Partition poststaskdb.posts_sample{month=05, year=2009} stats: [numFiles=1, numRows=111, totalSize=777, rawDataSize=666]\n",
      "Partition poststaskdb.posts_sample{month=05, year=2010} stats: [numFiles=1, numRows=168, totalSize=1344, rawDataSize=1176]\n",
      "Partition poststaskdb.posts_sample{month=05, year=2011} stats: [numFiles=1, numRows=327, totalSize=2616, rawDataSize=2289]\n",
      "Partition poststaskdb.posts_sample{month=05, year=2012} stats: [numFiles=1, numRows=429, totalSize=3861, rawDataSize=3432]\n",
      "Partition poststaskdb.posts_sample{month=05, year=2013} stats: [numFiles=1, numRows=520, totalSize=4680, rawDataSize=4160]\n",
      "Partition poststaskdb.posts_sample{month=05, year=2014} stats: [numFiles=1, numRows=541, totalSize=4869, rawDataSize=4328]\n",
      "Partition poststaskdb.posts_sample{month=05, year=2015} stats: [numFiles=1, numRows=566, totalSize=5094, rawDataSize=4528]\n",
      "Partition poststaskdb.posts_sample{month=05, year=2016} stats: [numFiles=1, numRows=603, totalSize=5427, rawDataSize=4824]\n",
      "Partition poststaskdb.posts_sample{month=06, year=2009} stats: [numFiles=1, numRows=120, totalSize=908, rawDataSize=788]\n",
      "Partition poststaskdb.posts_sample{month=06, year=2010} stats: [numFiles=1, numRows=201, totalSize=1608, rawDataSize=1407]\n",
      "Partition poststaskdb.posts_sample{month=06, year=2011} stats: [numFiles=1, numRows=340, totalSize=2720, rawDataSize=2380]\n",
      "Partition poststaskdb.posts_sample{month=06, year=2012} stats: [numFiles=1, numRows=412, totalSize=3708, rawDataSize=3296]\n",
      "Partition poststaskdb.posts_sample{month=06, year=2013} stats: [numFiles=1, numRows=477, totalSize=4293, rawDataSize=3816]\n",
      "Partition poststaskdb.posts_sample{month=06, year=2014} stats: [numFiles=1, numRows=487, totalSize=4383, rawDataSize=3896]\n",
      "Partition poststaskdb.posts_sample{month=06, year=2015} stats: [numFiles=1, numRows=570, totalSize=5130, rawDataSize=4560]\n",
      "Partition poststaskdb.posts_sample{month=06, year=2016} stats: [numFiles=1, numRows=584, totalSize=5256, rawDataSize=4672]\n",
      "Partition poststaskdb.posts_sample{month=07, year=2009} stats: [numFiles=1, numRows=133, totalSize=1064, rawDataSize=931]\n",
      "Partition poststaskdb.posts_sample{month=07, year=2010} stats: [numFiles=1, numRows=209, totalSize=1672, rawDataSize=1463]\n",
      "Partition poststaskdb.posts_sample{month=07, year=2011} stats: [numFiles=1, numRows=335, totalSize=2680, rawDataSize=2345]\n",
      "Partition poststaskdb.posts_sample{month=07, year=2012} stats: [numFiles=1, numRows=445, totalSize=4005, rawDataSize=3560]\n",
      "Partition poststaskdb.posts_sample{month=07, year=2013} stats: [numFiles=1, numRows=550, totalSize=4950, rawDataSize=4400]\n",
      "Partition poststaskdb.posts_sample{month=07, year=2014} stats: [numFiles=1, numRows=536, totalSize=4824, rawDataSize=4288]\n",
      "Partition poststaskdb.posts_sample{month=07, year=2015} stats: [numFiles=1, numRows=585, totalSize=5265, rawDataSize=4680]\n",
      "Partition poststaskdb.posts_sample{month=07, year=2016} stats: [numFiles=1, numRows=562, totalSize=5058, rawDataSize=4496]\n",
      "Partition poststaskdb.posts_sample{month=08, year=2008} stats: [numFiles=1, numRows=23, totalSize=133, rawDataSize=110]\n",
      "Partition poststaskdb.posts_sample{month=08, year=2009} stats: [numFiles=1, numRows=129, totalSize=1032, rawDataSize=903]\n",
      "Partition poststaskdb.posts_sample{month=08, year=2010} stats: [numFiles=1, numRows=212, totalSize=1696, rawDataSize=1484]\n",
      "Partition poststaskdb.posts_sample{month=08, year=2011} stats: [numFiles=1, numRows=362, totalSize=2896, rawDataSize=2534]\n",
      "Partition poststaskdb.posts_sample{month=08, year=2012} stats: [numFiles=1, numRows=445, totalSize=4005, rawDataSize=3560]\n",
      "Partition poststaskdb.posts_sample{month=08, year=2013} stats: [numFiles=1, numRows=531, totalSize=4779, rawDataSize=4248]\n",
      "Partition poststaskdb.posts_sample{month=08, year=2014} stats: [numFiles=1, numRows=495, totalSize=4455, rawDataSize=3960]\n",
      "Partition poststaskdb.posts_sample{month=08, year=2015} stats: [numFiles=1, numRows=554, totalSize=4986, rawDataSize=4432]\n",
      "Partition poststaskdb.posts_sample{month=08, year=2016} stats: [numFiles=1, numRows=571, totalSize=5139, rawDataSize=4568]\n",
      "Partition poststaskdb.posts_sample{month=09, year=2008} stats: [numFiles=1, numRows=89, totalSize=572, rawDataSize=483]\n",
      "Partition poststaskdb.posts_sample{month=09, year=2009} stats: [numFiles=1, numRows=128, totalSize=1024, rawDataSize=896]\n",
      "Partition poststaskdb.posts_sample{month=09, year=2010} stats: [numFiles=1, numRows=208, totalSize=1664, rawDataSize=1456]\n",
      "Partition poststaskdb.posts_sample{month=09, year=2011} stats: [numFiles=1, numRows=343, totalSize=2744, rawDataSize=2401]\n",
      "Partition poststaskdb.posts_sample{month=09, year=2012} stats: [numFiles=1, numRows=399, totalSize=3591, rawDataSize=3192]\n",
      "Partition poststaskdb.posts_sample{month=09, year=2013} stats: [numFiles=1, numRows=511, totalSize=4599, rawDataSize=4088]\n",
      "Partition poststaskdb.posts_sample{month=09, year=2014} stats: [numFiles=1, numRows=502, totalSize=4518, rawDataSize=4016]\n",
      "Partition poststaskdb.posts_sample{month=09, year=2015} stats: [numFiles=1, numRows=536, totalSize=4824, rawDataSize=4288]\n",
      "Partition poststaskdb.posts_sample{month=09, year=2016} stats: [numFiles=1, numRows=545, totalSize=4905, rawDataSize=4360]\n",
      "Partition poststaskdb.posts_sample{month=10, year=2008} stats: [numFiles=1, numRows=73, totalSize=511, rawDataSize=438]\n",
      "Partition poststaskdb.posts_sample{month=10, year=2009} stats: [numFiles=1, numRows=133, totalSize=1064, rawDataSize=931]\n",
      "Partition poststaskdb.posts_sample{month=10, year=2010} stats: [numFiles=1, numRows=222, totalSize=1776, rawDataSize=1554]\n",
      "Partition poststaskdb.posts_sample{month=10, year=2011} stats: [numFiles=1, numRows=331, totalSize=2648, rawDataSize=2317]\n",
      "Partition poststaskdb.posts_sample{month=10, year=2012} stats: [numFiles=1, numRows=469, totalSize=4221, rawDataSize=3752]\n",
      "Partition poststaskdb.posts_sample{month=10, year=2013} stats: [numFiles=1, numRows=570, totalSize=5130, rawDataSize=4560]\n",
      "Partition poststaskdb.posts_sample{month=10, year=2014} stats: [numFiles=1, numRows=527, totalSize=4743, rawDataSize=4216]\n",
      "Partition poststaskdb.posts_sample{month=10, year=2015} stats: [numFiles=1, numRows=561, totalSize=5049, rawDataSize=4488]\n",
      "Partition poststaskdb.posts_sample{month=10, year=2016} stats: [numFiles=1, numRows=554, totalSize=4986, rawDataSize=4432]\n",
      "Partition poststaskdb.posts_sample{month=11, year=2008} stats: [numFiles=1, numRows=54, totalSize=378, rawDataSize=324]\n",
      "Partition poststaskdb.posts_sample{month=11, year=2009} stats: [numFiles=1, numRows=149, totalSize=1192, rawDataSize=1043]\n",
      "Partition poststaskdb.posts_sample{month=11, year=2010} stats: [numFiles=1, numRows=236, totalSize=1888, rawDataSize=1652]\n",
      "Partition poststaskdb.posts_sample{month=11, year=2011} stats: [numFiles=1, numRows=361, totalSize=2888, rawDataSize=2527]\n",
      "Partition poststaskdb.posts_sample{month=11, year=2012} stats: [numFiles=1, numRows=438, totalSize=3942, rawDataSize=3504]\n",
      "Partition poststaskdb.posts_sample{month=11, year=2013} stats: [numFiles=1, numRows=543, totalSize=4887, rawDataSize=4344]\n",
      "Partition poststaskdb.posts_sample{month=11, year=2014} stats: [numFiles=1, numRows=501, totalSize=4509, rawDataSize=4008]\n",
      "Partition poststaskdb.posts_sample{month=11, year=2015} stats: [numFiles=1, numRows=529, totalSize=4761, rawDataSize=4232]\n",
      "Partition poststaskdb.posts_sample{month=11, year=2016} stats: [numFiles=1, numRows=562, totalSize=5058, rawDataSize=4496]\n",
      "Partition poststaskdb.posts_sample{month=12, year=2008} stats: [numFiles=1, numRows=51, totalSize=357, rawDataSize=306]\n",
      "Partition poststaskdb.posts_sample{month=12, year=2009} stats: [numFiles=1, numRows=147, totalSize=1176, rawDataSize=1029]\n",
      "Partition poststaskdb.posts_sample{month=12, year=2010} stats: [numFiles=1, numRows=237, totalSize=1896, rawDataSize=1659]\n",
      "Partition poststaskdb.posts_sample{month=12, year=2011} stats: [numFiles=1, numRows=350, totalSize=2800, rawDataSize=2450]\n",
      "Partition poststaskdb.posts_sample{month=12, year=2012} stats: [numFiles=1, numRows=415, totalSize=3735, rawDataSize=3320]\n",
      "Partition poststaskdb.posts_sample{month=12, year=2013} stats: [numFiles=1, numRows=513, totalSize=4617, rawDataSize=4104]\n",
      "Partition poststaskdb.posts_sample{month=12, year=2014} stats: [numFiles=1, numRows=482, totalSize=4338, rawDataSize=3856]\n",
      "Partition poststaskdb.posts_sample{month=12, year=2015} stats: [numFiles=1, numRows=537, totalSize=4833, rawDataSize=4296]\n",
      "Partition poststaskdb.posts_sample{month=12, year=2016} stats: [numFiles=1, numRows=195, totalSize=1755, rawDataSize=1560]\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1   Cumulative CPU: 10.14 sec   HDFS Read: 60003318 HDFS Write: 347805 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 10 seconds 140 msec\n",
      "OK\n",
      "Time taken: 32.681 seconds\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar]\n",
      "OK\n",
      "Time taken: 0.006 seconds\n",
      "Query ID = jovyan_20190218093636_997ee3e8-0e23-4787-8666-fa109d44693a\n",
      "Total jobs = 3\n",
      "Launching Job 1 out of 3\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1550229492569_0062, Tracking URL = http://82cdaacd7b39:8088/proxy/application_1550229492569_0062/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1550229492569_0062\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2019-02-18 09:36:26,601 Stage-1 map = 0%,  reduce = 0%\n",
      "2019-02-18 09:36:32,022 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.19 sec\n",
      "2019-02-18 09:36:38,254 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.41 sec\n",
      "MapReduce Total cumulative CPU time: 3 seconds 410 msec\n",
      "Ended Job = job_1550229492569_0062\n",
      "Launching Job 2 out of 3\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1550229492569_0063, Tracking URL = http://82cdaacd7b39:8088/proxy/application_1550229492569_0063/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1550229492569_0063\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2019-02-18 09:36:50,586 Stage-2 map = 0%,  reduce = 0%\n",
      "2019-02-18 09:36:54,834 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 0.83 sec\n",
      "2019-02-18 09:37:00,050 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.17 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 170 msec\n",
      "Ended Job = job_1550229492569_0063\n",
      "Launching Job 3 out of 3\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1550229492569_0064, Tracking URL = http://82cdaacd7b39:8088/proxy/application_1550229492569_0064/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1550229492569_0064\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "2019-02-18 09:37:11,707 Stage-3 map = 0%,  reduce = 0%\n",
      "2019-02-18 09:37:16,865 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 0.89 sec\n",
      "2019-02-18 09:37:22,052 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.56 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 560 msec\n",
      "Ended Job = job_1550229492569_0064\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.41 sec   HDFS Read: 387896 HDFS Write: 2499 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.17 sec   HDFS Read: 6488 HDFS Write: 2499 SUCCESS\n",
      "Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 2.56 sec   HDFS Read: 9638 HDFS Write: 16 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 8 seconds 140 msec\n",
      "OK\n",
      "Time taken: 64.993 seconds, Fetched: 1 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hive -f task1.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwS_Hbx3J5uL"
   },
   "source": [
    "Congratulations! You have completed the assignment! Now you can submit it to the system and get your results!\n",
    "\n",
    "Copy your notebook from the steps <a href=\"#Step-4.-Complete-the-assignment\">Step 4</a> and <a href=\"#Step-5.-Submission-part.-Do-not-touch!!-And-simple-run-all-cells-below!\">Step 5</a> to the new notebook. Run all the cells! And submit the copied notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "901_to_students.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
